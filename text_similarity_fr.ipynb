{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_similarity_fr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j7oIRKg4paX",
        "outputId": "4eaa1d2a-d22c-4f55-8ec9-64baeec2fdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# The original codes used here has been taken from: https://stackoverflow.com/a/24129170/16974310\n",
        "\n",
        "# Import packages\n",
        "import nltk, string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "fr_stopwords= stopwords.words('french')# stopwords for French\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from itertools import permutations, combinations\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
        "\n",
        "\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(item) for item in tokens]\n",
        "\n",
        "'''remove punctuation, lowercase, stem'''\n",
        "def normalize(text):\n",
        "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words=fr_stopwords)\n",
        "\n",
        "def cosine_sim(text1, text2):\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    return ((tfidf * tfidf.T).A)[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate similarity scores\n",
        "\n",
        "def generate_similarity_scores():\n",
        "    stemmer = nltk.stem.porter.PorterStemmer()\n",
        "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
        "\n",
        "    # Feed the text for comparison\n",
        "    t1=\"Je m’appelle L. J’ai 14 ans et j’habite dans un village près de Leicester. J’aime beaucoup faire de la peinture et du codage. Quand il fait beau, j’aime aller au parc avec mes amis. Au collège, j’aime l’art plastique et les science et la technologie.\"\n",
        "\n",
        "    t2=\"Je m’appelle A. J’ai 13 ans et j’habite dans un village près de Nottingham. J’aime beaucoup faire de la bricolage et codage. Quand il fait beau, j’aime aller au parc avec mes amis. Au collège, j’aime les sciences et la technologie.\"\n",
        "\n",
        "    t3=\"Je m’appelle K. J’ai 13 ans et j’habite à Loughborough. J’aime beaucoup faire de la musique, jouer aux échecs et faire de la natation.    Le weekend, j’aime aller en ville avec mes amis. Au collège, mes matières préférées sont les langues, l'histoire et la musique.\"\n",
        "    \n",
        "    # Generate combination of texts to check for similarity\n",
        "    texts = ['t1', 't2', 't3']\n",
        "    txt_combinations = []\n",
        "    for i in range(len(texts)):\n",
        "        cs = combinations(texts, i + 1)\n",
        "        for c in cs:\n",
        "          if len(c)==2: # allowing only 2 text combinations\n",
        "              txt_combinations.append(list(c))\n",
        "\n",
        "    # Print the combinations generated\n",
        "    print(f\"Text combinations generated are: {txt_combinations}\")\n",
        "    \n",
        "    # Iterate over each pair of texts to compute similarity between them\n",
        "    i=0\n",
        "    while i< len(txt_combinations):\n",
        "      print(f\"\\nChecking similarity between {txt_combinations[i][0]} & {txt_combinations[i][1]} - Detected {round(cosine_sim(eval(txt_combinations[i][0]),eval(txt_combinations[i][1]))*100,1)}% similarity\")    \n",
        "      i+=1\n",
        "\n",
        "\n",
        "# Function call\n",
        "generate_similarity_scores()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9OtV9kAHK_a",
        "outputId": "74ab45d2-716e-4760-9976-eca9b543fc02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text combinations generated are: [['t1', 't2'], ['t1', 't3'], ['t2', 't3']]\n",
            "\n",
            "Checking similarity between t1 & t2 - Detected 88.4% similarity\n",
            "\n",
            "Checking similarity between t1 & t3 - Detected 60.4% similarity\n",
            "\n",
            "Checking similarity between t2 & t3 - Detected 61.3% similarity\n"
          ]
        }
      ]
    }
  ]
}